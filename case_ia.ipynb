{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Introdu√ß√£o ao Aprendizado de M√°quina**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Antes de comer√ßarmos:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Neste curso, voc√™ ser√° exposto a diversos termos expressos em nota√ß√£o matem√°tica. Buscaremos sempre ilustrar de forma intuitiva o significado de cada uma dessas nota√ß√µes. No entanto, para avan√ßar no curso, √© fundamental dedicar um tempo para compreend√™-las, pois, √† medida que os modelos se tornam mais complexos, nem sempre ser√° poss√≠vel oferecer uma explica√ß√£o puramente intuitiva.\n",
    "\n",
    "Se voc√™ n√£o est√° familiarizado com nota√ß√£o matem√°tica ou sente receio ao v√™-la, n√£o se preocupe! Pense nela como uma forma compacta de expressar muitas informa√ß√µes em poucas palavras ‚Äî como uma linguagem pr√≥pria da matem√°tica. Encare isso como o aprendizado de um novo idioma. \n",
    "\n",
    "Boa sorte!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **O que √© Intelig√™ncia Artificial?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Diferen√ßas entre IA, Machine Learning e Deep Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Tipos de aprendizado de m√°quina**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **O que √© o Aprendizado Supervisionado?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **O que √© o Aprendizado N√£o Supervisionado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **O que √© o Aprendizado por Refor√ßo?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Defini√ß√µes iniciais**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que s√£o dados?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Imagine que voc√™ quer entender melhor um grupo de pessoas. \n",
    "\n",
    "Para isso, voc√™ decide anotar algumas informa√ß√µes sobre cada uma delas, como altura *(em cm)*, peso *(em kg)* e idade *(em anos)*. Voc√™ observa uma pessoa e registra esses tr√™s valores. Depois, faz o mesmo com outra pessoa e assim por diante.\n",
    "\n",
    "Cada conjunto de informa√ß√µes que voc√™ registra (neste caso, altura, peso e idade) constitui um **dado**, isto √©,uma representa√ß√£o de algo do mundo real que queremos estudar ou analisar.\n",
    "\n",
    "Suponha que coletamos os seguintes dados:\n",
    "\n",
    "- Pessoa 1: 170cm de altura, 70kg e 25 anos.\n",
    "\n",
    "- Pessoa 2: 160cm de altura, 55kg e 30 anos.\n",
    "\n",
    "- Pessoa 3: 180cm de altura, 80kg e 28 anos.\n",
    "\n",
    "Perceba que, com base nessas tr√™s informa√ß√µes podemos representar cada pessoa com tr√™s n√∫meros, veja:\n",
    "\n",
    "- Pessoa 1 -> (170, 70, 25).\n",
    "\n",
    "- Pessoa 2 -> (160, 55, 30).\n",
    "\n",
    "- Pessoa 3 -> (180, 80, 28).\n",
    "  \n",
    "Cada linha acima √© um conjunto de informa√ß√µes sobre uma pessoa.\n",
    "\n",
    "**Assim, o conjunto de dados que possu√≠mos √©: $$\\{(170,70,25),(160,55,30),(180,80,28)\\}$$**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que s√£o caracter√≠sticas?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Agora, perceba que cada dado √© formado por tr√™s n√∫meros diferentes. Cada um deles representa um tipo espec√≠fico de informa√ß√£o:\n",
    "\n",
    "- O primeiro n√∫mero indica a **altura**.\n",
    "\n",
    "- O segundo n√∫mero indica o **peso**.\n",
    "\n",
    "- O terceiro n√∫mero indica a **idade**.\n",
    "\n",
    "Chamamos essas informa√ß√µes individuais de **caracter√≠sticas**. Elas s√£o os aspectos que escolhemos para descrever cada pessoa.\n",
    "\n",
    "Se tiv√©ssemos escolhido outras informa√ß√µes, como cor dos olhos ou cidade onde mora, ter√≠amos caracter√≠sticas diferetentes. Assim, **as caracter√≠sticas s√£o os elementos que comp√µem cada dado.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que √© um espa√ßo de caracter√≠sticas?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Agora que compreendemos que, no exemplo que estamos usando, cada pessoa √© caracterizada por tr√™s atributos (altura, peso e idade), podemos pensar em um jeito de visualizar essas informa√ß√µes.\n",
    "\n",
    "Imagine um gr√°fico em que cada ponto representa uma pessoa, sendo descrita por tr√™s caracter√≠sticas: altura, peso e idade:\n",
    "\n",
    "- O **eixo X** representa a altura.\n",
    "\n",
    "- O **eixo Y** representa o peso.\n",
    "\n",
    "- O **eixo Z** representa a idade.\n",
    "\n",
    "Cada pessoa pode ser representada por um ponto dentro desse espa√ßo. **Esse espa√ßo, onde todas as combina√ß√µes poss√≠veis de altura, peso e idade podem existir‚Äîisto √©, onde essas caracter√≠sticas podem assumir quaisquer valores dentro de um intervalo permitido‚Äî√© chamado de espa√ßo de caracter√≠sticas.**  \n",
    "\n",
    "Se tiv√©ssemos apenas altura e peso, nosso espa√ßo teria apenas dois eixos, como um gr√°fico bidimensional. Se adicion√°ssemos mais caracter√≠sticas, precisar√≠amos de mais dimens√µes para representar tudo.\n",
    "\n",
    "üí° Dica: Tente visualizar esse conceito de forma gr√°fica: imagine um ponto em um espa√ßo tridimensional, onde o eixo X representa a altura, o eixo Y representa o peso e o eixo Z representa a idade. Esse ponto corresponde a uma pessoa dentro do nosso conjunto de dados. No in√≠cio, pode parecer desafiador imaginar esse espa√ßo, mas compreender essa ideia tornar√° o aprendizado muito mais intuitivo no futuro!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que s√£o vetores de caracter√≠sticas?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Agora que entendemos que cada pessoa √© representada por um ponto dentro do espa√ßo de caracter√≠sticas, podemos dar um nome especial para essa representa√ß√£o: **vetor de caracter√≠sticas**\n",
    "\n",
    "Um vetor de caracter√≠sticas √© simplesmente um conjunto de n√∫meros que descreve uma pessoa dentro desse espa√ßo. Podemos imagin√°-lo como uma \"seta\" que parte da origem do espa√ßo de caracter√≠sticas e aponta diretamente para a posi√ß√£o (coordenadas) correspondente a essa pessoa.\n",
    "\n",
    "Por exemplo, para a Pessoa 1, o vetor de caracter√≠sticas √© $(170, 70, 25)$, o que significa:\n",
    "\n",
    "- Altura: **170cm**.\n",
    "\n",
    "- Peso: **70kg**.\n",
    "\n",
    "- Idade: **25 anos**.\n",
    "\n",
    "Se pensarmos em um gr√°fico tridimensional, onde cada eixo representa uma caracter√≠stica (altura, peso e idade), esse vetor nos d√° a posi√ß√£o exata da pessoa nesse espa√ßo. A \"seta\" que parte da origem at√© esse ponto √© uma forma intuitiva de visualizar como cada observa√ß√£o do nosso conjunto de dados pode ser representada matematicamente.\n",
    "\n",
    "Em resumo, vetor de caracter√≠sticas √© um termo matem√°tico que usamos para representar cada observa√ß√£o dentro do nosso conjunto de dados.\n",
    "\n",
    "üí° Dica: Realmente tente imaginar que cada pessoa do nosso conjunto de dados √© representada por uma seta partindo da origem e apontando para um ponto no espa√ßo tridimensional. Essa seta nada mais √© do que o vetor de caracter√≠sticas, que indica a posi√ß√£o exata da pessoa nesse espa√ßo. No come√ßo, pode ser desafiador visualizar essa ideia, mas pensar nos vetores como \"setas direcionadas\" ajudar√° a compreender melhor como os dados s√£o organizados e analisados matematicamente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **O que √© um Algoritmo?**\n",
    "\n",
    "Um **algoritmo** √© um conjunto de **instru√ß√µes passo a passo** para resolver um problema ou realizar uma tarefa. Ele funciona como um guia que, quando seguido corretamente, leva a um resultado espec√≠fico.\n",
    "\n",
    "#### üç∞ **Exemplo Simples: Receita de Bolo**\n",
    "\n",
    "Imagine que voc√™ quer fazer um bolo. A **receita** √© o algoritmo, pois ela define o que voc√™ precisa fazer em cada etapa para alcan√ßar o objetivo final: o bolo pronto.\n",
    "\n",
    "#### **Passos do Algoritmo (Receita de Bolo):**\n",
    "1. **Pr√©-aque√ßa** o forno a 180¬∞C.  \n",
    "2. **Separe** os ingredientes: ovos, farinha, a√ß√∫car e fermento.  \n",
    "3. **Misture** os ovos e o a√ß√∫car at√© ficar homog√™neo.  \n",
    "4. **Adicione** a farinha e o fermento √† mistura.  \n",
    "5. **Despeje** a massa em uma forma untada.  \n",
    "6. **Asse** no forno por 40 minutos.  \n",
    "7. **Retire** o bolo do forno e **espere esfriar**.\n",
    "\n",
    "üí° **Resultado:** Um delicioso bolo pronto para ser servido!\n",
    "\n",
    "#### **Conclus√£o:**\n",
    "Assim como a receita garante que o bolo sair√° como esperado, um **algoritmo** garante que um problema ser√° resolvido de forma l√≥gica e organizada, seja em um programa de computador ou em tarefas do dia a dia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Formalizando as defini√ß√µes iniciais**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Agora que constru√≠mos uma boa intui√ß√£o, podemos formalizar esses conceitos matematicamente ‚Äî mantendo o formalismo apenas no n√≠vel necess√°rio por enquanto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- S√£o um conjunto de observa√ß√µes $X = \\{x_{1}, x_{2}, ..., x_{n}\\}$, onde cada $x_{i}$ √© uma observa√ß√£o.\n",
    "\n",
    "- No nosso exemplo, os dados s√£o o conjunto de pessoas que analisamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Caracter√≠sticas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- S√£o os atributos que usamos para descrever cada observa√ß√£o. \n",
    "  \n",
    "- Por exemplo, para a observa√ß√£o: $x_{i} = (x_{i1}, x_{i2},...,x_{id})$, cada valor $x_{ij}$ representa um atributo espec√≠fico da observa√ß√£o $x_{i}$ *(ex: altura, peso, idade)*, onde $j$ varia de $1$ at√© $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Espa√ßo de caracter√≠sticas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- √â o conjunto de todas as poss√≠veis combina√ß√µes dos atributos que utilizamos para descrever uma observa√ß√£o.\n",
    "\n",
    "- Se cada observa√ß√£o √© descrita por $d$ caracter√≠sticas, esse espa√ßo cont√©m todas as combina√ß√µes poss√≠veis desses $d$ atributos e √© matematicamente representado por $R^{d}$.\n",
    "\n",
    "- Intuitivamente, podemos imaginar esse espa√ßo como um ambiente onde cada observa√ß√£o ocupa uma posi√ß√£o √∫nica com base nos valores de suas caracter√≠sticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Vetores de caracter√≠sticas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Representam cada observa√ß√£o dentro do espa√ßo de caracter√≠sticas.\n",
    "\n",
    "- No nosso exemplo, a **Pessoa 1** √© representada pelo vetor: $x_{1} = (170,70,25) \\in R^{3}$.\n",
    "\n",
    "- De forma geral, para um espa√ßo de caracter√≠sticas com $d$ dimens√µes, cada observa√ß√£o √© um vetor da forma: $x_{i} = (x_{i1},x_{i2},...,x_{id}) \\in R^{d}$, onde $i$ indica o n√∫mero da observa√ß√£o e cada √≠ndice $j$ (com $j \\in \\{1,2,...,d\\}$) representa uma caracter√≠stica dessa observa√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Algoritmo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em **Machine Learning**, um **algoritmo** √© um conjunto de regras e procedimentos matem√°ticos e computacionais que orientam o processo de **aprendizado a partir de dados**. Ele define como o modelo deve analisar os dados de entrada, identificar padr√µes e fazer previs√µes ou classifica√ß√µes. Em outras palavras, o algoritmo √© a l√≥gica que ajusta os par√¢metros do modelo para minimizar erros e melhorar a precis√£o ao lidar com novos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### üí° Dica:\n",
    "\n",
    "N√£o se preocupe se essas defini√ß√µes parecerem um pouco abstratas no come√ßo! Voc√™ pode continuar avan√ßando no curso sem dominar completamente essas nota√ß√µes matem√°ticas. No entanto, quanto mais confort√°vel voc√™ estiver com essas nota√ß√µes, mais r√°pido ser√° seu progresso e mais profundo ser√° seu entendimento dos pr√≥ximos t√≥picos.\n",
    "\n",
    "Se algo n√£o ficou claro, pergunte ao respons√°vel pelo case e revise essas defini√ß√µes sempre que for estudar. Criar familiaridade com essas nota√ß√£os ao longo do tempo tornar√° o aprendizado muito mais natural e intuitivo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# **2. Fundamentos de Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **O que √© um modelo preditivo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um modelo preditivo √© um tipo de modelo de machine learning que tem como objetivo principal fazer previs√µes sobre novos dados com base em padr√µes aprendidos a partir de dados hist√≥ricos.\n",
    "\n",
    "---\n",
    "\n",
    "Esses modelos utilizam padr√µes extra√≠dos dos dados para fazer previs√µes sobre novas observa√ß√µes. Em termos formais, esses modelos buscam aprender uma fun√ß√£o $$f: x_{i} \\in X \\rightarrow Y$$ que relacione os vetores de caracter√≠sticas $x_{i} \\in X$ com a vari√°vel alvo $Y$, de forma que seja poss√≠vel estimar um $Y$ para um novo $x_{i} \\in X$ n√£o observado anteriormente.\n",
    "\n",
    "---\n",
    "\n",
    "Os modelos preditivos podem ser utilizados para diferentes tipos de tarefas, como prever se um cliente pagar√° um empr√©stimo (classifica√ß√£o), estimar o valor de um im√≥vel (regress√£o) ou antecipar o comportamento de uma s√©rie temporal (como pre√ßos de ativos financeiros).\n",
    "\n",
    "No entanto, as abordagens para construir esse tipo de modelo variam bastante, dependendo da forma como os dados s√£o tratados e da estrat√©gia utilizada para ajustar os par√¢metros do modelo. Podemos dividir os modelos preditivos em algumas categorias principais, s√£o elas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Modelos Estat√≠sticos e Probabil√≠sticos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses modelos assumem que os dados seguem uma distribui√ß√£o probabil√≠stica espec√≠fica e ajustam seus par√¢metros para maximizar a verossimilhan√ßa dos dados observados.\n",
    "\n",
    "‚úÖ **Objetivo:** Estimar a distribui√ß√£o dos dados e inferir a rela√ß√£o entre as vari√°veis.\n",
    "\n",
    "**Exemplos:**\n",
    "\n",
    "- Regress√£o Linear: Assume que a rela√ß√£o entre as vari√°veis √© linear e que os res√≠duos seguem uma distribui√ß√£o normal.\n",
    "\n",
    "- Regress√£o Log√≠stica: Usa a fun√ß√£o sigmoide para modelar probabilidades em problemas de classifica√ß√£o bin√°ria.\n",
    "\n",
    "- Na√Øve Bayes: Baseia-se na regra de Bayes e assume independ√™ncia condicional entre os atributos.\n",
    "\n",
    "üìå **Diferencial:** Esses modelos s√£o baseados em conceitos estat√≠sticos bem definidos e geralmente interpret√°veis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Modelos Baseados em Otimiza√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses modelos aprendem a fun√ß√£o $f$ otimizando uma m√©trica espec√≠fica, sem necessariamente assumir uma distribui√ß√£o subjacente dos dados.\n",
    "\n",
    "‚úÖ **Objetivo:** Encontrar um modelo que minimize uma fun√ß√£o de erro ou maximize uma margem de separa√ß√£o.\n",
    "\n",
    "**Exemplos:**\n",
    "\n",
    "- SVM (M√°quinas de Vetores de Suporte): Maximiza a margem entre as classes em problemas de classifica√ß√£o.\n",
    "\n",
    "- Redes Neurais (MLPs cl√°ssicas): Ajustam pesos para minimizar um erro atrav√©s do gradiente descendente.\n",
    "\n",
    "üìå **Diferencial:** Baseiam-se em t√©cnicas num√©ricas de otimiza√ß√£o e n√£o exigem uma suposi√ß√£o expl√≠cita sobre a distribui√ß√£o dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Modelos Baseados em Particionamento de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses modelos criam regras para dividir os dados em subconjuntos homog√™neos, organizando-os hierarquicamente.\n",
    "\n",
    "‚úÖ **Objetivo:** Criar regras de decis√£o que segmentem os dados em diferentes categorias.\n",
    "\n",
    "**Exemplos:**\n",
    "\n",
    "- √Årvores de Decis√£o: Criam um conjunto de regras sequenciais que levam a decis√µes.\n",
    "\n",
    "- Random Forests: Conjunto de √°rvores de decis√£o para aumentar a robustez.\n",
    "\n",
    "üìå **Diferencial:** S√£o f√°ceis de interpretar e n√£o exigem transforma√ß√µes matem√°ticas complexas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Modelos Baseados em Agrupamento (Clustering)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos que tentam encontrar padr√µes e estruturas nos dados sem r√≥tulos supervisionados.\n",
    "\n",
    "‚úÖ **Objetivo:** Agrupar os dados de forma a maximizar a semelhan√ßa dentro dos clusters e minimizar entre os clusters.\n",
    "\n",
    "**Exemplos:**\n",
    "\n",
    "- K-Means: Baseado na minimiza√ß√£o da soma das dist√¢ncias dos pontos ao centro do cluster.\n",
    "\n",
    "- DBSCAN: Detecta clusters com base na densidade dos dados.\n",
    "\n",
    "üìå **Diferencial:** √öteis para an√°lise explorat√≥ria e segmenta√ß√£o de dados sem supervis√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Modelos Baseados em Inst√¢ncias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses modelos fazem previs√µes baseadas nos exemplos mais pr√≥ximos no conjunto de treinamento, sem construir explicitamente uma fun√ß√£o generalizada durante o aprendizado.\n",
    "\n",
    "‚úÖ **Objetivo:** Utilizar diretamente os dados observados para fazer previs√µes sem uma fase expl√≠cita de aprendizado de par√¢metros.\n",
    "\n",
    "**Exemplo:**\n",
    "    \n",
    "- KNN (K-Nearest Neighbors): Classifica ou estima valores com base nos $k$ vizinhos mais pr√≥ximos.\n",
    "\n",
    "üìå Diferencial: S√£o conhecidos como modelos pregui√ßosos (lazy learners) porque n√£o possuem uma fase expl√≠cita de treinamento; todo o esfor√ßo computacional ocorre no momento da previs√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A import√¢ncia da amostra de treinamento para um modelo preditivo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No fim das contas, modelos preditivos tentam encontrar uma fun√ß√£o matem√°tica que capture a rela√ß√£o entre as vari√°veis de entrada (caracter√≠sticas) e a vari√°vel de sa√≠da (o que queremos prever). Essa fun√ß√£o pode ser vista como uma aproxima√ß√£o da verdadeira rela√ß√£o existente nos dados. No entanto, os dados usados para treinar o modelo representam apenas uma amostra de um conjunto muito maior e desconhecido. Se essa amostra for pequena, enviesada ou n√£o representativa, o modelo pode aprender padr√µes artificiais que n√£o se repetem em novos dados ‚Äî um problema conhecido como overfitting.\n",
    "\n",
    "Diferentes modelos fazem suposi√ß√µes distintas sobre essa rela√ß√£o. Modelos estat√≠sticos assumem que os dados seguem certas distribui√ß√µes probabil√≠sticas, enquanto modelos baseados em otimiza√ß√£o simplesmente ajustam fun√ß√µes para melhor se encaixar nos exemplos observados, sem pressupor uma estrutura fixa. Em ambos os casos, a qualidade da amostra influencia diretamente a capacidade do modelo de fazer boas previs√µes.\n",
    "\n",
    "Por isso, ao treinar um modelo, √© essencial garantir que os dados de entrada representem bem o fen√¥meno que estamos tentando modelar. M√©todos como valida√ß√£o cruzada, regulariza√ß√£o e aumento da diversidade dos dados ajudam a reduzir vieses e melhorar a capacidade do modelo de generalizar para novas situa√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Tradeoff entre Bias e Vari√¢ncia** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No contexto de machine learning, bias e variance s√£o conceitos centrais para entender o erro total de um modelo e avaliar sua capacidade de generaliza√ß√£o. Esses componentes descrevem como o modelo se comporta ao lidar com novos dados, ou seja, dados que n√£o foram usados durante o treinamento, e ajudam a identificar as causas de diferentes tipos de erro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Explicando o Bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O bias est√° associado √† incapacidade do modelo de captar as complexidades subjacentes nos dados. Modelos com alto bias fazem suposi√ß√µes simplificadas, resultando em um desempenho ruim tanto nos dados de treino quanto nos de teste. Esse comportamento caracteriza o subajuste (underfiting), quando o modelo n√£o consegue representar adequadamente as rela√ß√µes reais nos dados.\n",
    "\n",
    "Caracter√≠sticas do Bias:\n",
    "- Modelos com bias altos geralmente s√£o simples. Um exemplo √© a regress√£o linear aplicada quando os dados possuem rela√ß√µes **n√£o-lineares**\n",
    "- Ocorre quando o modelo subestima a complexidade das rela√ß√µes entre os dados\n",
    "- Est√° associada com baixa acur√°cia tanto nos dados de treino quanto nos dados de teste.\n",
    "\n",
    "A imagem abaixo deixa mais claro uma situa√ß√£o de um modelo com alto bias.\n",
    "\n",
    "<p align='center'>\n",
    "<img src=\"https://sigmoidal.ai/wp-content/uploads/2023/11/621609a7e64cfb63781a0426_24-300x200.png\" width=\"400\"></img>\n",
    "</p>\n",
    "\n",
    "Perceba que claramente h√° uma rela√ß√£o n√£o-linear entre os dados. Por√©m, o modelo tenta ajustar uma reta ao conjunto de dados, n√£o capturando toda a complexidade envolvida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defini√ß√£o formal de Bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O bias mede o erro sistem√°tico do modelo. Formalmente, ele se refere √† diferen√ßa entre o valor m√©dio das predi√ß√µes do modelo e o valor verdadeiro que estamos tentando prever. Matematicamente, para uma vari√°vel-alvo y, com base em entradas x, o bias √© definido como:\n",
    "\n",
    "$$\n",
    "\tBias(\\hat{f}(x)) = \\mathbb{E}[\\hat{f}(x)] - f(x)\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $E[\\hat{f}(x)]$ √© o valor esperado das predi√ß√µes do modelo (considerando diferentes amostras de treino).\n",
    "- $f(x)$ √© o verdadeiro mapeamento subjacente (fun√ß√£o real que gera os dados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Explicando a Vari√¢ncia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outro lado, a variancia reflete a sensibilidade do modelo √†s flutua√ß√µes nos dados de treino. Modelos com alta variancia n√£o apenas aprendem os padr√µes gerais, mas tamb√©m o ru√≠do espec√≠fico dos dados de treino. Isso resulta em um excelente desempenho nos dados de treino, mas um desempenho ruim em novos dados, caracterizando o superajuste (overfitting). \n",
    "\n",
    "Caracter√≠sticas da Variancia:\n",
    "\n",
    "- Modelos com variancia alta s√£o geralmente complexos, como √°rvores de decis√£o profundas ou redes neurais complexas treinadas com poucos dados.\n",
    "- Ocorre quando o modelo se ajusta excessivamente aos dados de treinamento.\n",
    "- Resulta em alta acur√°cia no **treinamento**, mas baixa acur√°cia em dados de **teste**, pois o modelo n√£o generaliza bem.\n",
    "\n",
    "\n",
    "A imagem abaixo mostra um exemplo de uma caso com alta variancia (overfitting):\n",
    "<p align='center'>\n",
    "<img src=\"https://cdn.prod.website-files.com/5fb24a974499e90dae242d98/621608ae7abbdc500080ef96_23.png\" width=\"400\"></img>\n",
    "</p>\n",
    "\n",
    "Neste caso, perceba que o modelo foca n√£o nas relac√µes fundamentais entre os dados, mas sim no r√∫ido espec√≠ficio dos dados de treino. Se formos aplicar esse modelo a uma outra amostra de dados que n√£o seja a de treino, o desempenho ser√° muito baixo, pois √© como se o modelo tivesse apenas memorizado o conjunto de treinamento.\n",
    "\n",
    "üí° **Dica**: Lembra daquela prova em que voc√™ teve pouco tempo de estudar e dois dias antes da prova bate aquele desespero? O que voc√™ faz? N√£o d√° tempo de entender todo o conte√∫do em t√£o pouco tempo.\n",
    "\n",
    "Uma alternativa nesse cen√°rio √© decorar aquela lista que o professor passou para estudo. Vai que cai uma quest√£o igualzinha n√©? \n",
    "\n",
    "Esse √© um caso em que voc√™ est√° em um overfitting!! Voc√™ pode ser capaz de responder cada quest√£o da lista de bate pronto, mas voc√™ n√£o entendeu o conte√∫do de fato, se houver alguma pergunta diferente, voc√™ n√£o saber√° responder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defini√ß√£o formal de Vari√¢ncia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A variancia mede a sensibilidade do modelo √†s flutua√ß√µes nos dados de treino. Ela descreve o quanto as predi√ß√µes do modelo variam em rela√ß√£o √† m√©dia das predi√ß√µes quando o modelo √© treinado com diferentes amostras de treino. Formalmente, a variancia √© definida como:\n",
    "\n",
    "$$\n",
    "\tVar(\\hat{f}(x)) = \\mathbb{E}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^{2}] \n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $\\hat{f}(x)$ √© a predi√ß√£o do modelo.\n",
    "- $\\mathbb{E}[\\hat{f}(x)]$ √© o valor esperado das predi√ß√µes do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Explicando o Tradeoff entre Bias e Vari√¢ncia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentalmente, a quest√£o de encontrar \"o melhor modelo\" se refere a encontrar um ponto √≥timo no trade-off entre bias e variancia\n",
    "\n",
    "A capacidade de generaliza√ß√£o de um modelo depende de encontrar um equil√≠brio entre bias e variancia. Um modelo com alto bias √© muito simples e subajusta os dados, enquanto um modelo com alta variancia √© excessivamente complexo e superajusta os dados de treino.\n",
    "\n",
    "O trade-off entre bias e variance refere-se ao equil√≠brio necess√°rio entre simplicidade e complexidade do modelo para alcan√ßar a melhor performance poss√≠vel.\n",
    "- üî∫Aumentar a complexidade de um modelo reduz o bias, mas aumenta a vari√¢ncia.\n",
    "- üîªSimplificar o modelo reduz a vari√¢ncia, mas aumenta o bias.\n",
    "\n",
    "O objetivo √© encontrar um ponto de equil√≠brio onde o modelo n√£o seja nem muito simples (evitando underfitting), nem excessivamente complexo (evitando overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Valida√ß√£o Cruzada e Overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Problemas de classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que √© um problema de classifica√ß√£o?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classifica√ß√£o √© o processo de reconhecimento, compreens√£o e agrupamento de objetos e ideias em categorias predefinidas. Utilizando conjuntos de dados de treinamento previamente categorizados, algoritmos de classifica√ß√£o em machine learning conseguem categorizar novos dados de forma precisa.\n",
    "\n",
    "Esses algoritmos analisam dados de entrada para prever a probabilidade de que novos dados perten√ßam a uma das categorias estabelecidas.\n",
    "\n",
    "Em termos simples, a classifica√ß√£o √© uma forma de reconhecimento de padr√µes, em que os algoritmos identificam padr√µes nos dados de treinamento e aplicam esse conhecimento a novos conjuntos de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motiva√ß√£o:** Suponha que voc√™ tenha um conjunto de dados com caracter√≠sticas de v√°rios clientes de um banco que desejam obter empr√©stimos. Seus dados possuem um conjunto de caracter√≠sticas desses clientes como idade, renda, n√≠vel de educa√ß√£o, entre outros. \n",
    "\n",
    "Baseando-se no conjunto de caracter√≠sticas fornecidas, voc√™ deseja **classificar** os clientes entre aqueles que ter√£o o empr√©stimo aprovado e aqueles que n√£o ter√£o o empr√©stimo aprovado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formalmente, em problemas de classifica√ß√£o o objetivo √© prever uma *class label*, uma lista de possibilidades pr√©-determinadas e que s√£o vari√°veis discretas.\n",
    "\n",
    "Na motiva√ß√£o acima, a nossa *class label* era se a pessoa teria o cr√©dito aprovado ou n√£o. Perceba que a resposta s√≥ assume dois valores poss√≠veis, sim ou n√£o (1 ou 0 em linguagem matem√°tica). Al√©m disso, podemos chamar essa vari√°vel de discreta porque ela s√≥ assume dois valores poss√≠veis, ela \"d√° um salto\" de 0 para 1.\n",
    "\n",
    "Os problemas de classifica√ß√£o podem ser separados em:\n",
    "\n",
    "- Classifica√ß√£o bin√°ria (binary classification)\n",
    "- Classifica√ß√£o multiclasse (Multi-class classification)\n",
    "- Classifica√ß√£o multir√≥tulo (Multi-label Classification)\n",
    "- Classifica√ß√£o desbalanceada (Imbalanced Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classifica√ß√£o bin√°ria (binary classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo da classifica√ß√£o bin√°ria √© classificar cada observa√ß√£o (vetor de caracter√≠sticas) tendo como possibilidade de resposta (label) exatamente duas classes. Voc√™ pode pensar na classifica√ß√£o bin√°ria como tentar responder uma pergunta do tipo sim ou n√£o. Um email √© um span? sim ou n√£o. Um cliente ter√° seu pedido de empr√©stimo aprovado? sim ou n√£o.\n",
    "\n",
    "Neste cen√°rio, podemos dizer que a class label √© mutuamente exclusiva. Ou seja, ou uma observa√ß√£o √© classificada como sim ou ela √© classifica como n√£o. √â imposs√≠vel uma observa√ß√£o ser classficadas como sim e n√£o ao mesmo tempo.\n",
    "\n",
    "üìù **Observa√ß√£o**: No contexto de classifica√ß√£o bin√°ria, √© comum usar True ou False, positivo ou negativo, 1 ou 0 para se referir a uma resposta do tipo \"sim ou n√£o\". N√£o se preocupe, s√£o apenas maneiras diferentes de se referir a mesma coisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classifica√ß√£o multiclasse (Multi-class classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semelhante a classifica√ß√£o bin√°ria, na classifica√ß√£o multiclasse tamb√©m queremos classificar cada observa√ß√£o no nosso conjunto de dados. Por√©m, nossa lista de possibilidades pr√©-determinadas agora √© maior que duas. Por√©m, de maneira semelhante, as class labels ainda s√£o mutuamente exclusivas e discretas.\n",
    "\n",
    "**Exemplo:** Se tivermos um conjunto de dados com caracter√≠sticas de alunos da FEA, podemos querer classific√°-los de acordo com o curso em que eles est√£o matriculados. As poss√≠veis respostas (class labels) s√£o (i) Administra√ß√£o, (ii) Economia, (iii) Contabilidade ou (iv) Atu√°ria. Perceba que um aluno n√£o pode estar matr√≠culado em dois ou mais destes cursos ao mesmo tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classifica√ß√£o multir√≥tulo (Multi-label Classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semelhante a classifica√ß√£o multiclasse, queremos classificar cada observa√ß√£o na nossa base de dados em uma lista de possibilidades pr√©-determinadas em duas ou mais class labels. Por√©m, no caso da classifica√ß√£o multir√≥tulo, as labels agora n√£o s√£o mais mutuamente exclusivas.\n",
    "\n",
    "Pense em um problema em que queremos classificar um vetor de caracter√≠stcas em X, Y, e/ou Z. Em um problema de multir√≥tulo, √© totalmente poss√≠vel que uma observa√ß√£o seja classficada como X e Y ou Y e Z **ao mesmo tempo**. Estranho n√©? Mas um exemplo deixa tudo mais claro.\n",
    "\n",
    "**Exemplo:** Pense agora que temos um conjunto de dados de v√°rios filmes e queremos classific√°-los de acordo com seus g√™neros. Perceba agora que os g√™neros de um filme n√£o s√£o mutuamente exclusivas, √© totalmente poss√≠vel que um filme seja de com√©dia e ao mesmo tempo seja um filme de a√ß√£o ou que um filme seja de terror e de suspense psicol√≥gico ao mesmo tempo. Ou seja, √© totalmente poss√≠vel que cada observa√ß√£o tenha uma ou mais label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classifica√ß√£o desbalanceada (Imbalanced Classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classifica√ß√£o desbalanceada n√£o √© exatamente uma categoria de classifica√ß√£o diferente, mas sim um ponto de aten√ß√£o que devemos ter quando trabalhamos com qualquer problema de classifica√ß√£o abordado nos t√≥picos anteriores.\n",
    "\n",
    "Ela acontece quando as class labels do nosso conjunto de dados n√£o est√° est√° balanceada. Neste caso, temos que as observa√ß√µes ser√£o classificadas majoritamente de um tipo e poucas ser√£o classificadas de outro.\n",
    "\n",
    "**Exemplo:** Suponha que uma doen√ßa rara afeta apenas 1% da popula√ß√£o.\n",
    "\n",
    "Se nossa base de dados de dados for representativa da popula√ß√£o, apenas cerca de 1% deveria ser classficado como positivo para a doen√ßa e 99% deveria ser negativo.\n",
    "\n",
    "Apesar de n√£o ser uma categoria diferenciada de classifica√ß√£o, √© importante que tenhamos no√ß√£o se estivermos trabalhando com um problema desse tipo porque as t√©cnicas e modelos usuais que veremos podem n√£o funcionar muito bem neste contexto. \n",
    "\n",
    "Outro ponto de aten√ß√£o necess√°rio √© quando tivermos avaliando um modelo nesse contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que √© um classificador?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um classificador √© um **algoritmo** de Machine Learning que √© utilizado para mapear cada vetor de caracter√≠sticas no conjunto de dados a uma categoria espec√≠fica. Conforme nossas defini√ß√µes iniciais, pense no classificador como um **conjunto de regras** que definem a metodologia utilizada para que o modelo que voc√™ est√° treinando produza o resultado esperado.\n",
    "\n",
    "Estes algoritmos, de maneira geral, implementam m√©todos matem√°ticos e estat√≠sticos sofisticados para classificar as observa√ß√µes do conjunto de dados.\n",
    "\n",
    "Alguns exemplos de classificadores que veremos ao longo do case s√£o:\n",
    "- KNN (K-Nearest Neighbor)\n",
    "- Naive Bayes\n",
    "- Regress√£o Log√≠stica\n",
    "- M√°quinas de Vetores de Suporte (SVC)\n",
    "- √Årvores de Decis√£o\n",
    "\n",
    "Passaremos em mais detalhes por cada um deles, ent√£o n√£o se preocupe em querer entender todos neste momento. Apenas tenha em mente que cada um desses classificadores segue um algoritmo espec√≠fico para produzir o resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **M√©tricas de Avalia√ß√£o para Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Acur√°cia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Acur√°cia √© o m√©todo mais simples e direto de se avaliar o resultado gerado por um modelo de Classifica√ß√£o\n",
    "\n",
    "Em resumo, ela mostra a **porcentagem de classifica√ß√µes corretas que o modelo fez**. Pensando de outra forma, a acur√°cia √© a **soma das previs√µes corretas** dividida pelo **total de previs√µes que o modelo fez**.\n",
    "\n",
    "A f√≥rmula que define a Acur√°cia √© a seguinte:\n",
    "\n",
    "$$\n",
    "ACC = \\frac{TP + TN}{TP + TN + FP + FN} \n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "$TP$ = True Positive, $TN$ = True Negative, $FP$ = False Positive, $FN$ = False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Precis√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refere-se √† propor√ß√£o de previs√µes positivas corretas em rela√ß√£o ao total de previs√µes positivas feitas pelo modelo. A f√≥rmula da m√©tricas de Precis√£o √© a seguinte:\n",
    "\n",
    "$$\n",
    "Precison = \\frac{TP} {TP + FP}\n",
    "$$\n",
    "\n",
    "A Precis√£o √© bastante usada quando o objetivo √© limitar o n√∫mero de falsos positivos. Um exemplo √© um modelo que tenta prever se um novo rem√©dio sera efetivo no tratamento de uma doen√ßa. Nesse caso, √© fundamental que o modelo minimize os falsos positivos para uma correta mensura√ß√£o da efic√°cia do rem√©dio. Esse √© um caso em que √© fundamental o modelo possuir uma alta precis√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Recall (ou Sensitivity)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, tamb√©m chamado de Sensitivity em alguns materiais, mede quanto das observa√ß√µes que s√£o positivas no conjunto de dados foram capturadas corretamente pelo modelo. \n",
    "\n",
    "$$\n",
    "Sensitivity=\\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Essa m√©trica √© crucial quando √© essencial capturar todos os casos positivos, como no diagn√≥stico de doen√ßas graves ou detec√ß√£o de fraudes. Ou seja, queremos minimizar a ocorr√™ncia de falsos negativos. No exemplo de diagn√≥stico de uma doen√ßa, √© fundamental que n√£o deixemos nenhum paciente doente n√£o ser identificado corretamente pelo modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù**Observa√ß√£o:**\n",
    "\n",
    "Existe um trade-off entre otimizar o **recall** e otimizar a **precis√£o**. √â poss√≠vel obter um recall perfeito de forma trivial se voc√™ prever que todas as amostras pertencem √† classe positiva ‚Äî dessa forma, n√£o haver√° falsos negativos, mas tamb√©m n√£o haver√° verdadeiros negativos. No entanto, ao prever todas as amostras como positivas, haver√° muitos falsos positivos, o que far√° com que a precis√£o seja muito baixa.\n",
    "\n",
    "Por outro lado, se voc√™ encontrar um modelo que prev√™ como positiva apenas a √∫nica amostra da qual tem total certeza (supondo que essa amostra seja realmente positiva) e classifica todas as outras como negativas, a precis√£o ser√° perfeita. Contudo, o recall ser√° muito ruim, pois o modelo deixar√° de identificar outras amostras positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **F1-Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos que tanto a Precis√£o quanto o Recall s√£o importantes medidas para avaliar um modelo de classifica√ß√£o. Como vimos, devemos fazer um trade-off entre as duas m√©tricas e analisar ambas para garantirmos que estamos com um bom modelo.\n",
    "\n",
    "Uma maneira de sumarizar ambas as m√©tricas em uma s√≥ √© o chamado **F1-Score**. Ele √© a m√©dia harmonica entre a Precis√£o e o Recall.\n",
    "\n",
    "$$\n",
    "F1-Score = {2}\\times{\\frac{\\text{Precision}\\times\\text{Recall}}{\\text{Precision}+\\text{Recall}}}\n",
    "$$\n",
    "\n",
    "O F1-Score pode ser uma medida melhor que a acur√°cia em conjunto de dados em classifica√ß√£o bin√°ria desbalanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Curva ROC-AUC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A curva ROC (Receiver Operation Characteristcs) √© uma curva em um gr√°fico que coloca a taxa de false positive (FPR) contra a taxa de true positive (TPR). Perceba que a taxa de true positive √© apenas outro nome para o Recall enquanto a taxa de false positive √© a fra√ß√£o de falsos positivos em rela√ß√£o a todos as observa√ß√µes classificadas como negativas na nossa base de dados. \n",
    "\n",
    "$$\n",
    "FPR = {\\frac{FP}{FP+TN}}\n",
    "$$\n",
    "\n",
    "<p align='center'>\n",
    "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjhApq1sW6tLaFEXU4jK9g5YzvQBsudIhRUNkSBSYldIPaQ1Rwny1Z7Sj-Rt_8W2CCVKGCMDqu5GoSu4Cao1rAkfwVjgPfINcRuJTGjR-JPXbxY7NtgKQbFYUT2z6IfOAaeZadKVjdvQlkSG7JbDntxsUXWatk1tOUk0XPGBzbnKIRL6f929n8u3Pk1alQf/s1600-rw/roc.png\" width=\"500\"></img>\n",
    "</p>\n",
    "\n",
    "Na curva ROC, a curva ideal √© pr√≥xima ao canto superior esquerdo. Perceba que pr√≥ximo deste ponto √© **maximizada** a taxa de True Positives e **minimizada** a taxa de False Positives.\n",
    "\n",
    "As vezes queremos resumir a informa√ß√£o fornecida pela curva ROC em um simples n√∫mero. √â aqui que entra a sigla AUC. Ela significa Area Under the Curve (√Årea abaixo da Curva). Ou seja, podemos calcular a √°rea abaixo da curva ROC para avaliarmos a qualidade do modelo.\n",
    "\n",
    "Intuitivamente, √© percept√≠vel que queremos que essa √°rea tenha o maior valor poss√≠vel. Isso acontece porque desejamos que a curva ROC alcance o mais pr√≥ximo poss√≠vel do canto superior esquerdo (no limite, chegando no n√∫mero 1 do eixo vertical). Dessa forma, quanto maior o valor da AUC, melhor a performance do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O classificador de Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Problemas de regress√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que √© um problema de regress√£o?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemas de regress√£o √© outro tipo de problemas dentro do campo do **aprendizado supervisionado**\n",
    "\n",
    "Se problemas de classifica√ß√£o √© quando queremos prever uma vari√°vel discreta (tamb√©m chamada de vari√°vel categorica), em problemas de **Regress√£o** o objetivo √© fazer previs√£o de uma **var√≠avel cont√≠nua**, ou uma vari√°vel do tipo float em termos de programa√ß√£o (ou uma vari√°vel real em termos mat√©maticos).\n",
    "\n",
    "Um exemplo cl√°ssico de um problema de regress√£o √© prever o sal√°rio de uma pessoa com base em um vetor de caracter√≠scas como a idade, anos de educa√ß√£o, √°rea de trabalho, entre outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Dica**: Uma maneira f√°cil de distinguir entre problemas de classifica√ß√£o e problema de regress√£o √© pensar se h√° continuidade ou se h√° algum \"salto\" na vari√°vel que voc√™ est√° tentando prever. No caso da renda de uma pessoa h√° claramente uma continuidade, uma pessoa pode ganhar R$ 3.000,00 ou R$ 3.001,00, e assim por diante. Teoricamente, h√° um conjunto infinito de valores a vari√°vel renda pode assuim. \n",
    "\n",
    "Por√©m, em problemas de classifica√ß√£o, h√° um claro salto na vari√°vel target. Se queremos prever, por exemplo, se uma pessoa ter√° um cr√©dito aprovado ou n√£o, s√≥ h√° duas respotas poss√≠vel, sim ou n√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que √© um regressor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De maneira semelhante a um classificador, um **regressor** √© um algoritmo de Machine Learning que mapeia cada vetor de caracter√≠sticas na base de dados a um output. Por√©m, neste caso, n√£o estamos mais falando de categorias e sim a um output cont√≠nuo. \n",
    "\n",
    "Os regressores tamb√©m se utilizam de m√©todos matem√°ticos e est√°tiscos para regredir uma vari√°vel target (tamb√©m chamada de vari√°vel dependente) a um vetor de caracter√≠sticas (vari√°veis independentes).\n",
    "\n",
    "Alguns dos principais regressores s√£o:\n",
    "- Regress√£o Linear\n",
    "- Lasso Regression\n",
    "- Ridge Regression\n",
    "- M√°quinas de Vetores de Suporte para Regress√£o (SVR)\n",
    "- √Årvores de Regress√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **M√©tricas de Avalia√ß√£o para Regress√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **MAE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Erro M√©dio Absoluto (MAE - Mean Squared Error), de maneira simplificada, mede a diferen√ßa m√©dia entro valor predito pelo modelo e o valor real observado. Por haver valores positivos e negativos, √© adicionado o m√≥dulo da diferen√ßa. Assim, queremos que o MAE tenha o menor valor poss√≠vel.\n",
    "\n",
    "A f√≥rmula do MAE √© a seguinte:\n",
    "\n",
    "$$\n",
    "MAE(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "Uma vantagem do MAE √© que sua escala √© a mesma dos dados, facilitando sua interpreta√ß√£o. Por exemplo, se estamos prevendo o sal√°rio e temos um MAE de 100, significa que, em m√©dia, o modelo tem um erro de R$100.00.\n",
    "\n",
    "a desvantagem do MAE √© que ele √© uma m√©trica n√£o afetada por outliers. Isso acontece porque cada erro tem possui o mesmo peso. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **MSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro quadr√°tico m√©dio (MSE ‚Äî Mean Squared Error) √© semelhante a m√©trica MAE, tamb√©m calculado o erro m√©dio do modelo entre o valor predito e o valor real. Por√©m, no MSE elevamos a diferen√ßa ao quadrado. A ideia por tr√°s disto √© penalizarmos valores que sejam muito diferentes entre o valor previsto e o valor real. Tamb√©m queremos que o MSE tenha o menor valor poss√≠vel.\n",
    "\n",
    "A f√≥rmula do MSE √© a seguinte:\n",
    "\n",
    "$$\n",
    "MSE(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Um desvantagem do MSE √© que, por elevarmos o valor ao quadrado, sua escala fica distorcida. Para contornar esse problema, podemos extrair a raiz do MSE. Oque nos leva a pr√≥xima m√©trica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **RMSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A raiz do erro quadr√°tico m√©dio (RMSE ‚Äî Root Mean Squared Error) √© basicamente o mesmo c√°lculo do MSE, onde queremos penalizar grandes diferen√ßas entre o valor previsto e o valor real. Mas, como j√° comentamos, extra√≠mos a raiz quadrado desse valor para lidar com o problema de interpreta√ß√£o das unidades. Ao fazermos isso, unidade fica na mesma escala do dado original.\n",
    "\n",
    "$$\n",
    "RMSE(y, \\hat{y}) = \\sqrt[]{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2)}\n",
    "$$\n",
    "\n",
    "üìù **Observa√ß√£o**: Apesar de estar na mesma unidade que o MAE, as m√©tricas costumam n√£o ter o mesmo valor. Isso vem do fato do RMSE estar capturando os outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MAPE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro percentual absoluto m√©dio (MAPE ‚Äî Mean Absolute Percentual Error) √© uma m√©trica que mostra a porcentagem de erro em rela√ß√£o aos valores reais. A ideia √© bastante parecida com as m√©tricas de erro m√©dio apresentadas anteriormente, por√©m aqui estamos pensando em termos percentuais. Ent√£o se tivermos um MAPE de 12% por exemplo, significa que o modelo faz, em m√©dia, previs√µes que diferem em 12% dos valores reais.\n",
    "\n",
    "A f√≥rmula do MAPE √©:\n",
    "\n",
    "$$\n",
    "\n",
    "MAPE(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} |\\frac{y_i - \\hat{y}_i}{y_i}| \\times 100\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **$R^{2}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A m√©trica $R^2$, representa o percentual de vari√¢ncia que √© explicada pelo modelo. Os resultados v√£o de 0 a 1 (ou de 0% a 100% em termos percentuais). Quanto maior o $R^2$, mais explicativo √© o modelo. \n",
    "\n",
    "A f√≥rmula √© a seguinte:\n",
    "\n",
    "$$\n",
    "R^2(y,\\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)2}{\\sum_{i=1}^{n} (y_i - \\overline{y}_i)^2}\n",
    "$$\n",
    "\n",
    "Podemos pensar no $R^2$ como o poder explicativo do seu modelo. No exemplo do sal√°rio, regredindo contra idade, anos de educa√ß√£o e setor de atividade. Se tivermos um $R^2$ de 60%, significa que nosso modelo explica 60% da varia√ß√£o do sal√°rio.\n",
    "\n",
    "Se isso for alto ou baixo, vai depender de outras m√©tricas e outros benchmarks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Feature Engineering √© o processo de extra√ß√£o, manipula√ß√£o e transforma√ß√£o de dados brutos, permitindo que esses dados se transformem em vari√°veis que um modelo de machine learning pode usar para alcan√ßar um objetivo desejado. A engenharia de recursos √© um desafio porque envolve uma combina√ß√£o de an√°lise de dados, conhecimento do dom√≠nio de neg√≥cios e certa intui√ß√£o.\n",
    "\n",
    "Pense que dados, por si s√≥, podem n√£o significar muita coisa. Esse problema se torna ainda mais agravante nos dias atuais quando pensamos na quantidade massiva de dados gerados na era do big data. Mais do que nunca, temos um mar de dados a nossa disposi√ß√£o. Por√©m, devemos pensar, como tirar valor disso? Podemos pensar no processo de **feature engineering** de forma abrangente, como a maneira de transformar **dados** em **informa√ß√£o**.\n",
    "\n",
    "Uma analogia √© imaginar o trabalho de um minerador de ouro. Ele extrai rochas brutas (dados) e precisa process√°-las para encontrar o ouro (informa√ß√£o √∫til). Do mesmo modo, a Feature Engineering extrai informa√ß√µes valiosas dos dados e traduz em uma linguagem que o modelo de machine learning consiga ler.\n",
    "\n",
    "<p align=center>\n",
    "<img src=\"https://www.kdnuggets.com/wp-content/uploads/Feature-Engineering.png\" width=600></img>\n",
    "<p>\n",
    "\n",
    "Existem algumas recomenda√ß√µes para uma feature engineering que sempre devemos seguir e iremos abordar elas nos pr√≥ximos t√≥picos. Por√©m, √© necess√°rio termos em mente que boa parte do processo de feature engineering vai variar em cada situa√ß√£o espec√≠fica e boa parte dela vem de termos criatividade e expertise para olharmos para nossos dados e imaginar como podemos extrair valor deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encoding**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De longe, a maneira mais comum de se representar vari√°veis categoricas √© utilizando encoding. Imagine que uma de suas features em sua base de dados √© uma coluna de n√≠vel educacional que possui como valores *Fundamental*, *Ensino M√©dio*, *Superior* e *P√≥s-Gradua√ß√£o*. Lembre-se que os modelos de machine learning nada mais s√£o do que algoritmos matem√°ticos/estat√≠sticos. Dessa forma, n√£o podemos utilizar vari√°veis textuais no modelo, precisamos traduzir isso em linguagem matem√°tica.\n",
    "\n",
    "\n",
    "#### **One-hot encoding**\n",
    "O m√©todo mais conhecido e utilizado √© o **one-hot encoding** que cria uma coluna bin√°ria para cada categoria. Essas colunas tamb√©m s√£o chamadas de vari√°veis dummies.\n",
    "\n",
    "No nosso exemplo, ter√≠amos uma coluna fundamental que receberia valor 1 para cada observa√ß√£o com este n√≠vel educacional e 0 caso contr√°rio, uma coluna ensino m√©dio com valor 1 para cada observa√ß√£o com esse n√≠vel educacional e 0 caso contr√°rio, e assim por diante.\n",
    "\n",
    "üìù **Observa√ß√£o**: Devemos ter cuidado ao aplicar o one-hot encoding para n√£o incorrermos no problema de multicolinearidade. Esse problema acontece quando uma coluna pode ser perfeitamente prevista a partir das outras. Isso cria redund√¢ncia nos dados e pode atrapalhar alguns modelos estat√≠sticos, como regress√£o linear, ao tornar os c√°lculos inst√°veis.\n",
    "\n",
    "no nosso exemplo a √∫ltima coluna (P√≥s-Gradua√ß√£o) pode ser perfeitamente inferida das outras tr√™s, pois P√≥s-Gradua√ß√£o = 1 - (Fundamental + Ensino M√©dio + Superior). Para contornamos esse problema, basta excluirmos uma coluna ao fazer o one-hot encoding\n",
    "\n",
    "#### **Label encoding**\n",
    "\n",
    "Outro m√©todo bastante utilizado para encoding √© o label encoding. De maneira simples, ele converte os valores de uma vari√°vel categorica em n√∫meros inteiros. No nosso exemplo, Fundamental poderia ser convertido para 0, Ensino m√©dio = 1, Superior = 2 e P√≥s-Gradua√ß√£o = 3.\n",
    "\n",
    "üìù **Observa√ß√£o**: Devemos ter o cuidado ao utilizar o label encoding porque os modelos podem interpretar essa transforma√ß√£o como uma rela√ß√£o ordinal. Por exemplo, o modelo pode entender que \"P√≥s-Gradua√ß√£o\" (3) √© tr√™s vezes mais importante do que \"Fundamental\" (0), o que pode levar a infer√™ncias incorretas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling √© o processo de transformar os valores n√∫mericos de uma base de dados para que eles fiquem dentro de uma mesma escala. Pense em uma base de dados em que temos idade e sal√°rio de v√°rias pessoas. A vari√°vel idade dever√° ter um range com algo em torno de 0 a 100, enquanto o sal√°rio pode ir de 0 a R$ 1.000.000,00 por exemplo. Muitos algoritmos de machine learning s√£o sens√≠veis a escalas diferentes entre os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Padroniza√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padroniza√ß√£o √© o processo de transformar a **distruibui√ß√£o** de uma vari√°vel de modo que ela tenha m√©dia 0 e desvio padr√£o 1. Esse √© um m√©todo que pode ser interessante de usar quando os dados possuem uma distribui√ß√£o normal ou quando h√° outliers, pois a m√©dia e o desvio padr√£o s√£o menos afetados que os valores extremos no Min-Max Scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses s√£o alguns m√©todos usuais de feature engineering, mas n√£o s√£o todos. Conforme ressaltado, a depender do problema em quest√£o voc√™ dever√° ter um pingo de criatividade para pensar formas diferentes de extrair informa√ß√£o contida nos dados. Por exemplo, muitas vezes voc√™ pode criar novas vari√°veis fazendo intera√ß√µes de vari√°veis em sua base.\n",
    "\n",
    "Sempre dedique um tempo especial a parte de feature engineering quando estiver desenvolvendo um modelo de machine learning, ela pode ser o diferencial para alcan√ßar um resultado satisfat√≥rio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# **3. Modelos para Problemas de Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **3.1 KNN (K-Nearest-Neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O KNN √© provavelmente o mais simples modelo de machine learning e geralmente o primeiro a ser apresentado nos materiais did√°ticos. Isso acontece por sua l√≥gica relativamente simples e de f√°cil entendimento. Basicamente, oque o modelo faz √© \"guardar\" os dados de treino e, toda vez que vai fazer uma predi√ß√£o, o algoritmo acha os dados \"mais pr√≥ximos\".\n",
    "\n",
    "Voltando a nossas defini√ß√µes iniciais, lembre-se que temos um *espa√ßo de caracter√≠sticas*. Cada observa√ß√£o em nossa base de dados √© representada por um *vetor de caracter√≠sticas* neste espa√ßo. Dessa forma, o KNN pega cada vetor desse na base de dados e coloca no espa√ßo de caracter√≠sticas. Quando for fazer uma previs√£o, ele coloca esse novo vetor de caracter√≠sticas a ser feito a previs√£o no espa√ßo e procura qual o vetor (ou vetores) de treino que est√£o **mais pr√≥ximos** desse novo vetor. Da√≠ o nome *nearest neighbor* (vizinho mais pr√≥ximo)\n",
    "\n",
    "O gif abaixo ilustra de maneira did√°tica esse processo:\n",
    "\n",
    "<p align=center>\n",
    "<img src=\"https://machinelearningknowledge.ai/wp-content/uploads/2018/08/KNN-Classification.gif\" width=600 height=400></img> </p>\n",
    "\n",
    "Na sua vers√£o mais simples, o algoritmo considera apenas um √∫nico vizinho mais pr√≥ximo. Por√©m, podemos passar qualquer valor arbitr√°rio k (da√≠ o K em K-Nearest Neighbor). Quando utilizamos mais de 1 vizinho, estamos meio que um sistema de votos para classificar o novo vetor de caracter√≠sticas. Ent√£o, para cada observa√ß√£o de teste, contamos quantos vizinhos pertencem a cada classe e classificamos essa observa√ß√£o como aquela que tiver a maior contagem.\n",
    "\n",
    "Quando estamos trabalhando com o modelo KNN, geralmente devemos nos preocupar com dois par√¢metros importantes: O n√∫mero de vizinhos e como calcular a dist√¢ncia entre os vetores. Quanto menor o n√∫mero de vizinhos, mais complexo √© o modelo e quanto maior o n√∫mero de vizinhos, mais simples ele √©. Para calcular a dist√¢ncia, usualmente a distancia euclidiana √© a mais utilizada.\n",
    "\n",
    "**Vantagens**: \n",
    "- O modelo KNN √© um modelo com algoritmo intuitivo e de f√°cil entendimento.\n",
    "- Capaz de capturar rela√ß√µes n√£o lineares entre os dados\n",
    "- F√°cil de implementar sem fazer muitos ajustes\n",
    "\n",
    "**Desvantagens**:\n",
    "- Lento quando temos um conjunto de dados de treino muito grande\n",
    "- Afetado por features com escalas muito diferentes\n",
    "- N√£o performa bem quando o conjunto de dados possui muitas features\n",
    "- √â particulamente ruim quando a maioria das features tem valor 0 na maior parte do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **3.2 Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos de classifica√ß√£o Naive Bayes s√£o modelos probabil√≠sticos constru√≠dos com base no **Teorema de Bayes**. Na classifica√ß√£o Bayeseana estamos interessados em calcular a probabilidade de certa observa√ß√£o pertencer a uma categoria (ou classe) dado as caracter√≠sticas observadas. Podemos escrever isso da seguinte forma $P(C_k | X)$ (Probabilidade da categoria k dado o vetor de caracter√≠sticas X)\n",
    "\n",
    "O Naive Bayes classifica uma amostra $X= (x_1, x_2, ..., x_n)$ atribuindo a classe $C_k$ que maximiza a probabilidade condicional:\n",
    "\n",
    "$$\n",
    "P(C_k|X) = \\frac{P(X|C_k)P(C_k)}{P(X)}\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $P(C_k|X)$: Probabilidade da classe $C_k$ dado os atributos $X$\n",
    "- $P(X|C_k)$: Probabilidade de observar os atributos $X$ na classe $C_k$\n",
    "- $P(C_k)$: Probabilidade pr√©via da classe $C_k$\n",
    "- $P(X)$: Probabilidade dos atributos $X$\n",
    "\n",
    "A predi√ß√£o √© feita escolhendo a classe que tem o maior valor de $P(C_k|X)$\n",
    "\n",
    "### **De onde v√™m o Naive (ing√™nuo) de Naive Bayes?**\n",
    "\n",
    "O Naive vem da principal hip√≥tese simplificadora que √© a suposi√ß√£o que as vari√°veis s√£o independentes entre si. Dessa forma, a probabilidade condicional se torna:\n",
    "\n",
    "$$\n",
    "P(X|C_k) = P(x_1|C_k)\\times P(x_2|C_k)\\times ... \\times P(x_n|C_k)\n",
    "$$\n",
    "\n",
    "Isso facilita os c√°lculos, pois agora basta calcular a probabilidade de cada feature separadamente.\n",
    "\n",
    "### **Gaussian Naive Bayes**\n",
    "\n",
    "Conforme dito, existem alguns modelos Naive Blayes classificadores. O primeiro √© o Gaussiano. De maneira simples, ele assume que os dados dentro de cada classe possui uma distribui√ß√£o Gaussiana (Normal). Assim, voc√™ pode treinar esse modelo achando a m√©dia e o desvio padr√£o dos dados dentro de cada classe. O Naive Bayes Gaussiano √© usado quando estamos trabalhando com dados cont√≠nuos\n",
    "\n",
    "### **Multinomial Naive Bayes**\n",
    "De maneira semelhante, classificadores Multinomial Naive Bayes assumem distribui√ß√£o multinomial. Assume que as features representam frequ√™ncias de contagem (Por exemplo, quantas vezes determinada palavra aparece em um email). Um dos usos mais comuns dos modelos multinomial √© na classifica√ß√£o de textos.\n",
    "\n",
    "### **Vantagens**:\n",
    "- Muito r√°pido tanto na etapa de treino quanto na etapa de teste\n",
    "- Usualmente s√£o f√°ceis de interpretar\n",
    "- H√° poucos hiperparametros para se preocupar (se √© que h√° algum)\n",
    "\n",
    "### **Desvantagens**:\n",
    "- Suposi√ß√£o ing√™nua de independ√™ncia entre as vari√°veis\n",
    "- N√£o funciona bem com dados altamente correlacionados\n",
    "- Pode haver problemas se os dados n√£o seguirem distribui√ß√£o guassiana (para dados cont√≠nuos)\n",
    "\n",
    "Em resumo, os modelos bayseanos, apesar de suas suposi√ß√µes que podem n√£o ser veross√≠meis na pr√°tica, usualmente fornecem bons resultados e podem ser considerados um bom benchmark para comparar outros modelos de classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **3.3 Regress√£o Log√≠stica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que √© Regress√£o Log√≠stica?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Regress√£o Log√≠stica √© um modelo matem√°tico usado para modelar a rela√ß√£o de uma vari√°vel categorica e um conjunto de vari√°veis independentes. Neste sentido, a regress√£o log√≠stica se assemelha muito com uma regress√£o linear, mas uma distin√ß√£o importante √© que a sa√≠da de um modelo de regress√£o log√≠stica nos fornece a **probabilidade** de ocorr√™ncia de uma categoria.\n",
    "\n",
    "Esse tipo de modelo estat√≠stico (tamb√©m conhecido como modelo logit) frequentemente √© usado para classifica√ß√£o bin√°ria e an√°lise preditiva. Como o resultado √© uma probabilidade, a vari√°vel dependente √© limitada entre 0 e 1.\n",
    "\n",
    "Para calcular essa probabilidade, a regress√£o log√≠stica mapeia y como uma **fun√ß√£o sigmoide** de x:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "Se imaginarmos que o conjunto x possui apenas uma vari√°vel e tra√ßarmos uma curva, teremos o seguinte resultado:\n",
    "\n",
    "<p align=center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ac/Logistic-curve.png\" width=600 height=400></img> </p>\n",
    "\n",
    "Perceba que os poss√≠veis resultados da vari√°vel dependente est√£o limitados entre 0 e 1.\n",
    "\n",
    "A sa√≠da do modelo √© uma probabilidade, e a classifica√ß√£o √© feita com um limiar (threshold), geralmente 0.5:\n",
    "\n",
    "- Se $P(Y=1) \\geq 0.5$, ent√£o classe ser√° 1\n",
    "- se $P(Y=1) < 0.5$, ent√£o classe ser√° 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Interpreta√ß√£o dos coeficientes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reescrever a equa√ß√£o de regress√£o log√≠stica da seguinte forma:\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{P(Y=1)}{1 - P(Y=1)}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- $( P(Y=1))$ √© a probabilidade do evento ocorrer.\n",
    "- $\\frac{P(Y=1)}{1 - P(Y=1)}$ representa a raz√£o de chances. (Odds Ratio (raz√£o de chances))\n",
    "- $( \\log(\\frac{P(Y=1)}{1 - P(Y=1)} ))$ √© a transforma√ß√£o logar√≠tmica da raz√£o de chances (Logaritmo da odds, que se relaciona linearmente com as vari√°veis preditoras.)\n",
    "\n",
    "$\\beta_0$ (Intercepto): epresenta o logaritmo da odds quando todas as vari√°veis preditoras $X_i = 0$. Ap√≥s a exponencia√ß√£o, fornece a odds base do evento ocorrer na aus√™ncia de influ√™ncias das vari√°veis.\n",
    "\n",
    "Se por exemplo. tivermos $\\beta_1 = 0.3$, teremos que para cada aumento de 1 unidade em $X_1$, o logaritmo da raz√£o de chances aumenta em $0.3$\n",
    "\n",
    "Para interpretar diretamente o efeito da vari√°vel na raz√£o de chances (odds ratio). Aplicamos a exponencia√ß√£o: $e^{\\beta_i}$\n",
    "\n",
    "No exemplo em que $\\beta_1 = 0.3$, ter√≠amos que $e^{\\beta_1} = e^{0.3} = 1.35$. Intepretamos assim que, para cada aumento adicional em $X$ as probabilidades do evento positivo aumentam em $35%$.\n",
    "\n",
    "\n",
    "#### **Vantagens**:\n",
    "\n",
    "- R√°pido na etapa de treinamento e na etapa de teste\n",
    "- F√°cil interpreta√ß√£o\n",
    "- Sa√≠da probabil√≠stica\n",
    "\n",
    "#### **Desvantagens**::\n",
    "- Assune rela√ß√£o linear entre as features\n",
    "- N√£o funciona bem quando as vari√°veis s√£o muito correlacionadas\n",
    "- N√£o funciona bem com alta dimensionalidade das features\n",
    "- Poss√≠vel vi√©s com classes desbalanceadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Aplica√ß√µes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Regress√£o Log√≠stica Bin√°ria**\n",
    "\n",
    "A regress√£o log√≠stica bin√°ria funciona bem para problemas de classifica√ß√£o bin√°ria que tenham apenas dois resultados poss√≠veis. A vari√°vel dependente pode ter apenas dois valores, como sim e n√£o ou 0 e 1.\n",
    "\n",
    "#### **Regress√£o Log√≠stica Multinomial**\n",
    "\n",
    "A regress√£o multinomial pode analisar problemas que tenham v√°rios resultados poss√≠veis, desde que o n√∫mero de resultados seja finito. Por exemplo, ela √© capaz de prever se os pre√ßos das casas aumentar√£o em 25%, 50%, 75% ou 100% com base em dados populacionais, mas n√£o pode prever o valor exato de uma casa.\n",
    "\n",
    "#### **Regress√£o Log√≠stica Ordinal**\n",
    "\n",
    "A regress√£o log√≠stica ordinal, ou o modelo logit ordenado, √© um tipo especial de regress√£o multinomial para problemas em que os n√∫meros representam classifica√ß√µes em vez de valores reais. Por exemplo, voc√™ usaria a regress√£o ordinal para prever a resposta a uma pergunta de pesquisa que pede para os clientes classificarem seu servi√ßo como ruim, regular, bom ou excelente com base em um valor num√©rico, como o n√∫mero de itens que eles compram de voc√™ ao longo do ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **3.4 M√°quinas de Vetores de Suporte para Classifica√ß√£o (SVC)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problemas linearmente separ√°veis e n√£o linearmente separ√°veis**\n",
    "\n",
    "Um problema √© considerado **linearmente separ√°vel** quando existe uma linha, plano ou hiperplano que pode dividir as classes de dados de forma clara, sem sobreposi√ß√£o, no espa√ßo de caracter√≠sticas. Nesse cen√°rio, todas as inst√¢ncias de uma classe est√£o de um lado do limite de decis√£o, e as inst√¢ncias da outra classe est√£o do outro lado.\n",
    "\n",
    "**Exemplo**: Imagine um conjunto de dados 2D onde um grupo de pontos (classe A) est√° no lado esquerdo de uma linha e outro grupo de pontos (classe B) est√° no lado direito. Nesse caso, o problema pode ser resolvido por um classificador linear.\n",
    "\n",
    "Quando as classes de dados n√£o podem ser separadas por uma linha ou plano no espa√ßo original, o problema √© **n√£o linearmente separ√°vel**. Isso ocorre quando as classes est√£o dispostas de forma complexa, como em padr√µes curvos, agrupamentos sobrepostos ou em espirais.\n",
    "\n",
    "**Exemplo**: Imagine dois conjuntos de pontos no plano 2D, onde um forma um c√≠rculo dentro do outro. Nenhuma linha reta pode separar essas classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classificadores de M√°xima Margem**\n",
    "\n",
    "Os classificadores de m√°xima margem s√£o algoritmos de aprendizado de m√°quina usados para classifica√ß√£o, cujo objetivo √© encontrar a melhor separa√ß√£o entre diferentes classes, garantindo a maior separa√ß√£o poss√≠vel entre os pontos mais pr√≥ximos de cada classe, pontos esses conhecidos como vetores de suporte.\n",
    "\n",
    "Uma fraqueza dos classificadores de m√°xima margem √© que eles s√£o muito sens√≠veis a outliers. Um outlier pode alterar consideravelmente a margem de classifica√ß√£o, levando-o pr√≥ximo de outra classe. Isso faz com que o modelo classifique incorretamente pontos que est√£o pr√≥ximos √† fronteira de separa√ß√£o, mesmo que esses pontos estejam, na pr√°tica, mais alinhados com a outra classe.\n",
    "\n",
    "Em uma dimens√£o, o classificador √© um ponto (um subespa√ßo de dimens√£o 0, no jarg√£o matem√°tico).\n",
    "\n",
    "Em duas dimens√µes, o classificador √© uma reta(um subespa√ßo de dimens√£o 1, no jarg√£o matem√°tico).\n",
    "\n",
    "Em tr√™s dimens√µes, ele √© um plano (um subespa√ßo de dimens√£o 2, no jarg√£o matem√°tico).\n",
    "\n",
    "Em quatro ou mais dimens√µes, o classificador se torna um hiperplano, (que √© um subespa√ßo de uma dimens√£o a menos que o espa√ßo de entrada, no jarg√£o matem√°tico)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Soft Margin**\n",
    "\n",
    "O conceito de Soft Margin (margem suave) √© uma abordagem utilizada para lidar com dados n√£o perfeitamente separ√°veis. Ele permite que alguns pontos violem a margem ou at√© mesmo fiquem do lado \"errado\" do hiperplano de separa√ß√£o.\n",
    "\n",
    "Perceba que o conceito de **soft margin** est√° intimamente conectado ao **Bias-variance tradeoff**.\n",
    "\n",
    "De modo geral, uma soft margin √© uma adapta√ß√£o da margem m√°xima que aceita que alguns pontos caiam dentro da margem ou do lado incorreto do hiperplano. Isso equilibra o Bias-variance tradeoff, reduzindo o risco de overfitting.\n",
    "\n",
    "Por fim, ao utilizar a soft margin, √© comum que os outliers sejam acomodados dentro da margem ou at√© classificados incorretamente, dependendo de sua posi√ß√£o em rela√ß√£o ao hiperplano. Essa flexibilidade √© intencional e visa priorizar a generaliza√ß√£o do modelo em vez de uma separa√ß√£o perfeita nos dados de treinamento. Como resultado, os modelos com soft margin demonstram maior robustez frente a ru√≠dos e valores discrepantes, mantendo bom desempenho mesmo em cen√°rios com dados imperfeitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que √© Support Vector Classification (SVC)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O SVC (Support Vector Classifier) √© um algoritmo de aprendizado de m√°quina supervisionado baseado na M√°quina de Vetores de Suporte (SVM - Support Vector Machine) para tarefas de classifica√ß√£o. Ele busca encontrar um hiperplano √≥timo que separa os dados em diferentes classes com m√°xima margem. A margem √© a dist√¢ncia entre o hiperplano de separa√ß√£o e os pontos mais pr√≥ximos de cada classe, conhecidos como vetores de suporte, que s√£o fundamentais para definir a posi√ß√£o e orienta√ß√£o do hiperplano.\n",
    "\n",
    "O SVC √© projetado para equilibrar a precis√£o na classifica√ß√£o dos dados de treinamento com a capacidade de generaliza√ß√£o para novos dados, fundamentando-se em dois conceitos principais: a margem m√°xima e a soft margin. Embora seja classificado como um classificador de m√°xima margem, ele apresenta adapta√ß√µes que o tornam mais robusto para lidar com dados reais.\n",
    "\n",
    "Em situa√ß√µes ideais, onde os dados s√£o linearmente separ√°veis e livres de ru√≠do ou outliers, o SVC funciona como um classificador de m√°xima margem tradicional. Nesse contexto, o modelo busca um hiperplano que separa perfeitamente as classes, garantindo que nenhum ponto caia dentro da margem ou do lado errado do hiperplano.\n",
    "\n",
    "No entanto, em cen√°rios reais, os dados frequentemente apresentam outliers ou ru√≠do, e as classes podem n√£o ser perfeitamente separ√°veis. Para lidar com essas limita√ß√µes, o SVC incorpora o conceito de soft margin, permitindo certa flexibilidade na defini√ß√£o da margem. Essa abordagem tolera erros, como pontos que ficam dentro da margem (entre o hiperplano e os vetores de suporte) ou que s√£o classificados incorretamente.\n",
    "\n",
    "A imagem abaixo deixa mais claro uma situa√ß√£o hipot√©tica do processo de separa√ß√£o de classes de um SVC:\n",
    "<p align=center>\n",
    "<img src=\"https://www.iunera.com/wp-content/uploads/image-16-1024x756.png?v=1596602837\" width=600 height=400></img> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Fun√ß√µes kernel (linear, polinomial, radial)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Support Vector Machines e o Kernel Trick**\n",
    "\n",
    "O maior avan√ßo das SVMs sobre os classificadores tradicionais √© o uso do **kernel trick**. Quando os dados n√£o s√£o linearmente separ√°veis no espa√ßo original, os SVMs podem usar uma t√©cnica chamada kernel trick para mapear os dados para um espa√ßo de maior dimens√£o onde eles podem ser separ√°veis de forma linear. Al√©m dessa ideia brilhante, o kernel trick possui uma outra sacada muito inteligente: Em vez de calcular diretamente as coordenadas no novo espa√ßo, o kernel calcula o **produto interno** entre os pontos de dados mapeados, sem a necessidade de realizar a transforma√ß√£o expl√≠cita. Isso torna o processo mais eficiente e permite a cria√ß√£o de fronteiras de decis√£o n√£o lineares.\n",
    "\n",
    "O conceito central √© que muitos algoritmos de aprendizado de m√°quina, incluindo as SVMs, dependem do c√°lculo de dist√¢ncias ou rela√ß√µes geom√©tricas entre pontos de dados. Para isso, o produto interno entre dois vetores √© frequentemente utilizado. Esse produto interno nos d√° uma medida de similaridade entre os vetores, o que √© crucial para definir a posi√ß√£o relativa dos pontos em rela√ß√£o ao hiperplano de separa√ß√£o.\n",
    "\n",
    "O truque do kernel resolve esse problema de forma elegante: ele utiliza uma **fun√ß√£o kernel** que calcula diretamente o produto interno dos dados como se estivessem no espa√ßo de dimens√£o superior, sem jamais realizar a transforma√ß√£o expl√≠cita. Em outras palavras, o kernel fornece o valor que seria obtido ap√≥s o mapeamento, mas sem a necessidade de realmente mapear os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **O que s√£o fun√ß√µes Kernel?**\n",
    "\n",
    "As fun√ß√µes kernel s√£o t√©cnicas utilizadas em M√°quinas de Vetores de Suporte (SVM) e outros modelos de aprendizado de m√°quina para transformar dados n√£o linearmente separ√°veis em um espa√ßo de maior dimens√£o onde possam ser linearmente separados.\n",
    "\n",
    "Elas permitem que o classificador SVM trabalhe com separa√ß√µes n√£o lineares, sem precisar explicitamente mapear os dados para um espa√ßo de alta dimens√£o.\n",
    "\n",
    "Em vez de calcular diretamente as coordenadas dos dados em um espa√ßo de maior dimens√£o, o kernel calcula o produto interno entre os pontos transformados, o que simula como se os dados estivessem em uma dimens√£o superior. O kernel ‚Äúfaz isso‚Äù atrav√©s de uma fun√ß√£o matem√°tica que, ao ser aplicada nos pontos, √© capaz de calcular o produto interno correspondente ao espa√ßo de maior dimens√£o sem precisar realmente fazer essa transforma√ß√£o.\n",
    "\n",
    "**Os principais tipos de kernels s√£o**:\n",
    "\n",
    "**Kernel Linear**: Quando os dados j√° s√£o linearmente separaveis:\n",
    "\n",
    "$$K(x, x') = x \\cdot x'$$\n",
    "\n",
    "**Kernel polinomial**: Quando h√° rela√ß√µes polinomiais entre classes\n",
    "\n",
    "$$K(x, x') = (x \\cdot x' + c)^d$$\n",
    "\n",
    "**Kernel RBF(Radial Basis Function)**: \tQuando os dados n√£o seguem um padr√£o linear\n",
    "\n",
    "$$K(x, x') = \\exp(-\\gamma ||x - x'||^2)$$\n",
    "\n",
    "Em muitos casos, o kernel RBF (Gaussiano) √© o mais usado, pois funciona bem para uma ampla variedade de problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **3.5 √Årvores de Decis√£o para Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Conceito de Decision Trees para Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Årvores de decis√£o √© um tipo de modelo n√£o param√©trico utilizado para fazer classifica√ß√£o baseado em **condi√ß√µes sequencias**. Essencialmente, podemos pensar nesse tipo de modelo como uma sequ√™ncia de quest√µes do tipo **if/else**, levando a uma decis√£o final. Um modelo de √°rvore de decis√£o tenta aprender qual sequ√™ncia de quest√µes if/else nos leva a o resultado desejado de forma mais r√°pida.\n",
    "\n",
    "Para v√°riaveis categoricas, podemos pensar que as quest√µes feitas ser√£o do tipo sim ou n√£o. Por exemplo, \"essa vari√°vel pertence a classe 1? se (if) sim ..., se n√£o (else)...\"\n",
    "\n",
    "J√° para vari√°veis cont√≠nuas, as perguntas feitas tem a finalidade de dividir a decis√£o tendo como condicional um threshold para dividir os dados. Por exemplo, \"essa vari√°vel i √© maior que o valor x? se(if) sim ..., se n√£o (else)...\"\n",
    "\n",
    "Algumas terminologias importantes:\n",
    "- **N√≥ (node)**: Pontos onde as quest√µes if/else s√£o feitas\n",
    "- **Folhas (leafs)**: Representam o resultado final das quest√µes feitas\n",
    "\n",
    "Em uma √°rvore de decis√£o bem feita, cada n√≥ (quest√£o) ir√° cortar o n√∫mero de decis√µes pela metade, aproximadamente. O ponto principal, no final das contas, √© o modelo conseguir aprender quais s√£o as quest√µes **√≥timas** a se fazer.\n",
    "\n",
    "Vamos utilizar um exemplo simples para ilustrar uma √°rvore de decis√£o. Imagine que voc√™ est√° decidindo se ir√° a praia e, para isso, ir√° considerar duas vari√°veis: Se h√° vento e se h√° sol. A √°rvore de decis√£o para essa situa√ß√£o est√° ilustrada abaixo:\n",
    "\n",
    "<p align=center>\n",
    "<img src=\"https://didatica.tech/wp-content/uploads/2020/07/image-3.png\" width=500 height=300></img> </p>\n",
    "\n",
    "No n√≥ inicial, voc√™ se pergunta: H√° sol? Se n√£o houver sol, voc√™ vai para o ramo da direita e decide n√£o ir a praia. Por√©m, se houver sol, voc√™ vai para o ramo da esquerda e faz a pr√≥xima pergunta: Est√° ventando? Mais uma vez, caso a resposta seja sim, voc√™ decide n√£o ir a praia. Por√©m, se n√£o estiver ventando, voc√™ decidir√° ir a praia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Classification Trees**\n",
    "\n",
    "As **√°rvores de classifica√ß√£o** s√£o um tipo de √°rvore de decis√£o projetada para categorizar dados em diferentes classes. Elas funcionam dividindo os dados em subconjuntos baseados em condi√ß√µes espec√≠ficas, representadas por regras de \"se-ent√£o\". O objetivo final √© determinar a classe mais prov√°vel de um dado, com base nos valores de suas caracter√≠sticas. As folhas da √°rvore representam as classes finais, enquanto os n√≥s internos cont√™m condi√ß√µes que guiam o processo de decis√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Crit√©rios de divis√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Crit√©rio de Gini**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Impureza**\n",
    "\n",
    " A **Impureza** em uma √°rvore de decis√£o √© uma medida da heterogeneidade ou mistura das classes em um conjunto de dados em um determinado n√≥ da √°rvore. Ela quantifica o grau de incerteza associado √† distribui√ß√£o das classes no n√≥, ou seja, o qu√£o \"confuso\" ele √© em termos de pertencer predominantemente a uma √∫nica classe. Quanto menor a impureza, mais homog√™neo √© o n√≥ e mais confiante o modelo pode estar ao classificar uma inst√¢ncia que atinge aquele n√≥.\n",
    "\n",
    "##### **Por que a impureza √© importante?**\n",
    "\n",
    "A impureza √© usada durante o treinamento para determinar as condi√ß√µes de divis√£o nos n√≥s. O objetivo de uma √°rvore de classifica√ß√£o √© criar n√≥s que sejam os mais homog√™neos poss√≠veis em rela√ß√£o √†s classes. Isso significa que, ap√≥s cada divis√£o, os subconjuntos resultantes devem ter impureza reduzida em compara√ß√£o com o n√≥ original. Essa redu√ß√£o na impureza √© conhecida como ganho de informa√ß√£o ou redu√ß√£o de Gini, dependendo do crit√©rio escolhido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **√çndice de Gini**\n",
    "O √çndice de Gini mede a probabilidade de um elemento ser classificado incorretamente se for escolhido aleatoriamente de um conjunto de dados. Ou seja, ele avalia o qu√£o misturadas est√£o as classes dentro de um n√≥.\n",
    "\n",
    "A f√≥rmula do √çndice de Gini para um n√≥ $t$ √©:\n",
    "\n",
    "$$ G = 1 - \\sum\\limits_{i = i}^{k} p_{i}^{2} $$ \n",
    "\n",
    "Onde:\n",
    "- $p_i$ √© a propor√ß√£o de elementos da classe $i$ no conjunto de dados do n√≥.\n",
    "- $C$ √© o n√∫mero total de classes\n",
    "\n",
    "O valor do √≠ndice varia entre 0 e 1:\n",
    "- **0 (pureza m√°xima)**: Todos os elementos pertencem a uma √∫nica classe.\n",
    "- **Pr√≥ximo de 1 (impureza m√°xima)**: As classes est√£o distribu√≠das de forma uniforme.\n",
    "\n",
    "Caso o n√≥ possua ramifica√ß√µes, o seu **√çndice de Gini** ser√° dado pela m√©dia ponderada dos √çndices de Gini de seus dois n√≥s filhos, ou seja:\n",
    "\n",
    "$$\n",
    "G_{total} = (\\dfrac{n_{a}}{n_{a}+n_{b}}) \\cdot G_{A} + (\\dfrac{n_{b}}{n_{a}+n_{b}}) \\cdot G_{B}\n",
    "$$\n",
    "Onde:\n",
    "- $G_{A}$ √© o √çndice de Gini do n√≥ filho $A$\n",
    "- $G_{B}$ √© o √çndice de Gini do n√≥ filho $B$ \n",
    "- $(\\dfrac{n_{a}}{n_{a}+n_{b}})$  e  $(\\dfrac{n_{b}}{n_{a}+n_{b}})$ s√£o as propor√ß√µes de inst√¢ncias nas folhas $A$ e $B$, respectivamente.\n",
    "\n",
    "**Interpreta√ß√£o:**\n",
    "\n",
    "- Se as duas folhas tiverem uma grande diferen√ßa no n√∫mero de inst√¢ncias, a folha com mais inst√¢ncias ter√° um peso maior no √≠ndice de Gini final da ramifica√ß√£o.\n",
    "- Quanto mais homog√™neo for um n√≥ filho (ou seja, quanto mais as inst√¢ncias de uma √∫nica classe estiverem concentradas nesse n√≥), menor ser√° o √≠ndice de Gini desse n√≥. Isso implica que a impureza do n√≥ filho ser√° reduzida. Como resultado, se ambos os n√≥s filhos forem homog√™neos, a ramifica√ß√£o como um todo ter√° uma impureza menor, o que, por sua vez, reduz a impureza do n√≥ pai e melhora a qualidade da divis√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Entropia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropia pode ser definida como a medida que nos diz o quanto nossos dados est√£o desorganizados e misturados. Quanto maior a entropia, menor o ganho de informa√ß√£o e vice-versa. Nossos dados ficam menos entr√≥picos conforme dividimos os dados em conjuntos capazes de representar apenas uma classe do nosso modelo.\n",
    "\n",
    "A f√≥rmula da entropia √© a seguinte:\n",
    "\n",
    "$$H(S) = - \\sum_{i=1}^{C} p_i \\log_2(p_i)$$\n",
    "\n",
    "Onde:\n",
    "- $p_i$ √© a propor√ß√£o de elementos da classe $i$.\n",
    "- $C$ √© o n√∫mero total de classes\n",
    "\n",
    "Se todos os exemplos pertencem √† mesma classe (ou seja, n√£o h√° incerteza), a entropia √© zero. Se h√° uma divis√£o uniforme entre diferentes classes, a entropia √© m√°xima.\n",
    "\n",
    "Perceba que tanto o √≠ndice de Gine quanto a entropia s√£o muito semelhantes. Por√©m, o √≠ndice de Gini √© baseado na teoria da probabilidade e mede impureza como a probabilidade de erro na classifica√ß√£o. J√° a entropia v√™m da teoria da informa√ß√£o e mede a impureza com base nela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Poda e Overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema de overfitting costuma ser um ponto de grande aten√ß√£o em modelos de √°rvores de decis√£o. Pense que, no limite, podemos fazer quantas perguntas do tipo if/else quisermos e iremos conseguir classificar os dados de treino de forma quase perfeita. Quando isso acontece, temos uma √°rvore t√£o profunda que ela passa a focar no ru√≠do particular dos dados de treino ao inv√©s das rela√ß√µes fundamentais entre os dados. Dessa forma, o modelo ir√° falhar ao tentar generalizar para novos dados. \n",
    "\n",
    "Em uma √°rvore de decis√£o, o overfitting pode ocorrer quando a √°rvore √© constru√≠da com profundidade excessiva, ou seja, quando ela continua dividindo os dados at√© o ponto em que cada folha cont√©m apenas uma inst√¢ncia de dados ou poucas inst√¢ncias. Isso leva a um modelo que √© extremamente sens√≠vel a pequenas varia√ß√µes nos dados de entrada e pode n√£o ser robusto o suficiente para fazer previs√µes precisas em dados n√£o vistos.\n",
    "\n",
    "**Poda (post-pruning)**:\n",
    "\n",
    "Uma das estrat√©gias para controlar o overfiting √© a chamada **poda**. Basicamente, ela consiste em, ap√≥s a constru√ß√£o da √°rvore, remover n√≥s que tragam pouca informa√ß√£o para a decis√£o final (pense mesmo na analogia com a poda de uma √°rvore). Isso √© feito para simplificar a √°rvore e reduzir sua complexidade.\n",
    "\n",
    "**Limitar o tamanho da √°rvore (pr√©-pruning):**\n",
    "\n",
    "Outro tipo de poda poss√≠vel √©, antes de criarmos a √°rvore, limitar a profundida m√°xima da √°rvore ou o n√∫mero m√≠nimo de itens classificados dentro de uma categoria. Assim, conseguimos impedir que a √°rvore cres√ßa demais e impedindo o overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **3.6 M√©todos de Ensemble para Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Bagging para Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Boosting para Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **AdaBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Stochastic Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **XGBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Stacking para Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **3.7 An√°lise Discriminante**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **An√°lise Discriminante Linear (LDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **An√°lise Discriminante Quadr√°tica (QDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Projeto de Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Objetivos:**\n",
    "\n",
    "1. Compara√ß√£o entre os modelos\n",
    "\n",
    "2. Aprender a como escolher o melhor modelo para um problema\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# **4. Modelos para Problemas de Regress√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **4.1 Modelos Lineares para Regress√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Regress√£o Linear Simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Regress√£o Linear M√∫ltipla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Regress√£o com Regulariza√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Lasso Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **4.2 M√°quinas de Vetores de Suporte para Regress√£o (SVR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **O que √© Support Vector Regression (SVR)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Aplica√ß√£o e Hiperpar√¢metros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **4.3 √Årvores de Regress√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Conceito de Decision Trees para Regress√£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Crit√©rios de divis√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **MAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Poda e Overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **4.4 M√©todos de Ensemble para Regress√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Bagging para Regress√£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Boosting para Regress√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **AdaBoost Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Gradient Boosting Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Stochastic Gradient Boosting Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **XGBoost Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Projeto de Regress√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Objetivos:**\n",
    "\n",
    "1. Compara√ß√£o entre os modelos\n",
    "\n",
    "2. Aprender a como escolher o melhor modelo para um problema\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Aprendizado N√£o Supervisionado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Sistemas de recomenda√ß√£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
